# -*- coding: utf-8 -*-
"""Tokenization using nltk.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mgIn5gvJInpYuwu_Bry28zhCANL4RwKV
"""

import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from  nltk.probability import FreqDist
import matplotlib.pyplot as plt

text = 'Hello Mr Imran, how are you doing today? The weather is good and the city is great. The sky is blue'

# Tokenizing text

tokenized_text = sent_tokenize(text) 

print("Tokenized text ==> ",tokenized_text)

# Tokenizing words

tokenized_word = word_tokenize(text)

print("Tokenized word ==> ",tokenized_word)

#FreqDist 

fdist = FreqDist(tokenized_word)

print("FreqDist ===> ", fdist)

#freq with 21 samples and 24 outcomes 

fdist.most_common(2)

[('is',3),(',', 2)]

fdist.plot(30, cumulative=False)
plt.show()

from nltk.corpus import stopwords
stop_words = set(stopwords.words('english'))

filtered_sent=[]

for w in tokenized_word:
    if w not in stop_words:
        filtered_sent.append(w)

print("Tokenized Sentence ==> ",tokenized_word)
print("Filtered Sentence ==> ",filtered_sent)

from nltk.stem import PorterStemmer
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import sent_tokenize, word_tokenize

ps = PorterStemmer()
lemmatizer = WordNetLemmatizer()

new_text = 'It is important to be very honest and work hard while you are studying.'
words = word_tokenize(new_text)

for w in words:
    print(words)

for w in words:
    print(ps.stem(w))


for w in words:
    print(lemmatizer.lemmatize(w,"v"))

import nltk
from nltk.tokenize import PunktSentenceTokenizer

train_text = 'This is a test.'
sample_text = 'This is very good that POS tagging works'

custom_sent_tokenizer = PunktSentenceTokenizer(train_text)

tokenized = custom_sent_tokenizer.tokenize(sample_text)

def process_content():
    try:
        for i in tokenized:
            words =nltk.word_tokenize(i)
            tagged = nltk.pos_tag(words)
            print(tagged)
    
    except Exception as e:
        print(str(e))

process_content()